# CUDA Kernels

| Day | Topic |
|-----|-------|
| 1 | [RGB to Grayscale Conversion](Day01/notes.md) |
| 2 | [Vector Addition](Day02/notes.md) |
| 3 | [Error Handling in CUDA](Day03/notes.md) |
| 4 | [SIMD and SPMD Implementations](Day04/notes.md) |
| 5 | [Matrix Addition](Day05/notes.md) |
| 6 | [Matrix Multiplication](Day06/notes.md) |
| 7 | [Memory Types in CUDA](Day07/notes.md) |
| 8 | [Tiled Matrix Multiplication](Day08/notes.md) |
| 9 | [Matrix Transpose](Day09/notes.md) |
| 10 | [1D Convolution](Day10/notes.md) |
| 11 | [2D Convolution](Day11/notes.md) |
| 12 | [Parallel Prefix Sum](Day12/notes.md) |
| 13 | [Image Downsampling](Day13/notes.md) |
| 14 | [Histogram Calculation](Day14/notes.md) |
| 15 | [Sparse Matrix-Vector Multiplication](Day15/notes.md) |
| 16 | [Alternating Least Squares](Day16/notes.md) |
| 17 | [ALS with Bias](Day17/notes.md) |
| 18 | [Collaborative Filtering Implementation](Day18/notes.md) |
| 19 | [Merge Sort](Day19/notes.md) |
| 20 | [Fast Hadamard Transform](Day20/notes.md) |
| 21 | [Loop Unrolling Optimizations](Day21/notes.md) |
| 22 | [Forward Convolution](Day22/notes.md) |
| 23 | [Max Pooling and Image Unrolling](Day23/notes.md) |
| 24 | [Convolution Backward Pass](Day24/notes.md) |
| 25 | [ReLU Forward and Backward](Day25/notes.md) |
| 26 | [CNN Implementation](Day26/notes.md) |
| 27 | [Softmax Implementation](Day27/notes.md) |
| 28 | [Layer Normalization](Day28/notes.md) |
| 29 | [K-Means Clustering](Day29/notes.md) |
| 30 | [GELU Activation](Day30/notes.md) |
| 31 | [Gaussian Filter](Day31/notes.md) |
| 32 | [ReLU Optimization](Day32/notes.md) |
| 33 | [Binary Cross Entropy](Day33/notes.md) |
| 34 | [BCE Optimization](Day34/notes.md) |
| 35 | [BCE with Softmax](Day35/notes.md) |
| 36 | [Gaussian High Boost Filter](Day36/notes.md) |
| 37 | [CUDA Graphs](Day37/notes.md) |
| 38 | [cuBLAS Vector Addition](Day38/notes.md) |
| 39 | [cuBLAS Matrix Multiplication](Day39/notes.md) |
| 40 | [Rotary Position Embedding (RoPE)](Day40/notes.md) |
| 41 | [Gradient Descent vs Momentum](Day41/notes.md) |
| 42 | [SwiGLU Activation](Day42/notes.md) |
| 43 | [GeGLU Activation](Day43/notes.md) |
| 44 | [Ray Tracing](Day44/notes.md) |
| 45 | [3-Body Problem Simulation](Day45/notes.md) |
| 46 | [Wavefunction Evolution](Day46/notes.md) |
| 47 | [Game of Life](Day47/notes.md) |
| 48 | [Conjugate Gradient Method](Day48/notes.md) |
| 49 | [Linear System Solver](Day49/notes.md) |
| 50 | [Matrix Inversion](Day50/notes.md) |
| 51 | [Radix Sort](Day51/notes.md) |
| 52 | [FFT for Audio Processing](Day52/notes.md) |
| 53 | [Voronoi Diagram](Day53/notes.md) |
| 54 | [Mandelbrot Set](Day54/notes.md) |
| 55 | [Dynamic Time Warping](Day55/notes.md) |
| 56 | [Neural Style Transfer](Day56/notes.md) |
| 57 | [AdaHessian Optimizer](Day57/notes.md) |
| 58 | [L-BFGS Optimizer](Day58/notes.md) |
| 59 | [Quasi-Newton Method](Day59/notes.md) |
| 60 | [Symbolic Differentiation](Day60/notes.md) |
| 61 | [Evolutionary Algorithm](Day61/notes.md) |
| 62 | [Self-Organizing Maps](Day62/notes.md) |
| 63 | [Spiking Neural Network](Day63/notes.md) |
| 64 | [Hyper Network](Day64/notes.md) |
| 65 | [Wasserstein Distance ](Day65/notes.md) |
| 66 | [LoRA ](Day66/notes.md) |
| 67 | [Hebbian leearning rule ](Day67/notes.md) |
| 68 | [Leaky integrate and fire ](Day68/notes.md) |
| 69 | [Vector Similarity  ](Day69/notes.md) |
| 70 | [Auo regrressive forecast ](Day70/notes.md) |
| 71 | [Image binarization ](Day71/notes.md)
| 72 | [tokenizer ](Day72/notes.md)
| 73 | [Attention score matrix ](Day73/notes.md)
| 74 | [PCA ](Day74/notes.md)
| 75 | [Embeeding lookup](Day75/notes.md)
| 76 | [cosine similarity ](Day76/notes.md)
| 77 | [Hierarchical Navigable Small World ](Day77/notes.md)
| 78 | [Sparse attention](Day78/notes.md)
| 79 | [Residual connection](Day79/notes.md)
| 80 | [flash attention forward ](Day80/notes.md)
| 81 | [flash attention backward](Day81/notes.md)
| 82 | [Attention linear biases](Day82/notes.md)
| 83 | [GQA](Day83/notes.md)
| 84 | [LLM Quant](Day84/notes.md)
| 85 | [Gradient Checkpoint](Day85/notes.md)
| 86 | [Token Merging](Day86/notes.md)
| 87 | [TV Distance](Day87/notes.md)
| 88 | [JS Divergence](Day88/notes.md)
| 89 | [MROPE](Day89/notes.md)
| 90 | [Fused Linear Softmax](Day90/notes.md)
| 91 | [Contrastive loss ](Day91/notes.md)
| 92 | [Triplet loss ](Day92/notes.md)
| 93 | [upper triangular matmul](Day93/notes.md)
| 94 | [huber loss](Day94/notes.md)
| 95 | [matmul_swish](Day95/notes.md)
| 96 | [softplus](Day96/notes.md)
| 97 | [negative cosine similarity](Day97/notes.md)
| 97 | [negative cosine similarity](Day97/notes.md)
| 97 | [negative cosine similarity](Day97/notes.md)

























